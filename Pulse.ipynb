{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_5bPIdlDVmJI",
    "outputId": "1c570a43-7a05-4a2f-8495-b99d3d614f8c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting openai\n",
      "  Downloading openai-0.27.4-py3-none-any.whl (70 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.3/70.3 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting aiohttp\n",
      "  Downloading aiohttp-3.8.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m20.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from openai) (4.65.0)\n",
      "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.9/dist-packages (from openai) (2.27.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests>=2.20->openai) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests>=2.20->openai) (2022.12.7)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests>=2.20->openai) (2.0.12)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests>=2.20->openai) (1.26.15)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->openai) (23.1.0)\n",
      "Collecting multidict<7.0,>=4.5\n",
      "  Downloading multidict-6.0.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.2/114.2 kB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting yarl<2.0,>=1.0\n",
      "  Downloading yarl-1.9.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (269 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m269.4/269.4 kB\u001b[0m \u001b[31m27.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting async-timeout<5.0,>=4.0.0a3\n",
      "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
      "Collecting frozenlist>=1.1.1\n",
      "  Downloading frozenlist-1.3.3-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (158 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.8/158.8 kB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting aiosignal>=1.1.2\n",
      "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Installing collected packages: multidict, frozenlist, async-timeout, yarl, aiosignal, aiohttp, openai\n",
      "Successfully installed aiohttp-3.8.4 aiosignal-1.3.1 async-timeout-4.0.2 frozenlist-1.3.3 multidict-6.0.4 openai-0.27.4 yarl-1.9.2\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "_sKW_hVNNYXg"
   },
   "outputs": [],
   "source": [
    "import openai\n",
    "import json\n",
    "import moviepy.editor as mp\n",
    "\n",
    "openai.api_key = 'OPEN API KEY'\n",
    "video_file_name = 'Finance.mp4' #'phone review.mp4'\n",
    "video_end_sec = 60\n",
    "audio_file_name = video_file_name.split('.')[0] + '.mp3'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "983wthz3HPel",
    "outputId": "bbb14a6a-7598-4f06-e386-bf3f934c08ba"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Writing audio in Finance.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n"
     ]
    }
   ],
   "source": [
    "clip = mp.VideoFileClip(video_file_name)\n",
    "duration = 800 #clip.duration\n",
    "\n",
    "mod_clip = clip.subclip(0,duration)\n",
    "\n",
    "mod_clip.audio.write_audiofile(audio_file_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "lO7PDvUiV5eu"
   },
   "outputs": [],
   "source": [
    "audio_file= open(audio_file_name, \"rb\")\n",
    "\n",
    "transcript = openai.Audio.transcribe(\"whisper-1\", audio_file)\n",
    "\n",
    "# Convert the JSON object to a JSON-formatted string\n",
    "transcript = json.dumps(transcript)\n",
    "# Save to txt file\n",
    "with open(\"input.txt\", \"w\") as file:\n",
    "    file.write(transcript)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "GLx3SMhTYSkj"
   },
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "import nltk\n",
    "\n",
    "def generate_sentiment_score(paragraph):\n",
    "    \n",
    "    # Tokenize sentences\n",
    "    review = nltk.sent_tokenize(paragraph)\n",
    "\n",
    "    prompt = f\"Give me the sentiment score(1-10) of the following review, just give me a number': {review}\"\n",
    "    \n",
    "    response = openai.Completion.create(\n",
    "        engine=\"text-davinci-003\",\n",
    "        prompt=prompt,\n",
    "        max_tokens=50,\n",
    "        n=1,\n",
    "        stop=None,\n",
    "        temperature=0.7,\n",
    "    )\n",
    "        \n",
    "    summary = response.choices[0].text.strip()\n",
    "    return summary\n",
    "\n",
    "def generate_topic(paragraph):\n",
    "    \n",
    "    # Tokenize sentences\n",
    "    review = nltk.sent_tokenize(paragraph)\n",
    "\n",
    "    prompt = f\"Give me the topic of the following review, within 3 words': {review}\"\n",
    "    \n",
    "    response = openai.Completion.create(\n",
    "        engine=\"text-davinci-003\",\n",
    "        prompt=prompt,\n",
    "        max_tokens=50,\n",
    "        n=1,\n",
    "        stop=None,\n",
    "        temperature=0.7,\n",
    "    )\n",
    "        \n",
    "    summary = response.choices[0].text.strip()\n",
    "    return summary\n",
    "\n",
    "def generate_theme(paragraph):\n",
    "    \n",
    "    # Tokenize sentences\n",
    "    review = nltk.sent_tokenize(paragraph)\n",
    "\n",
    "    prompt = f\"Give me a theme of the following review': {review}\"\n",
    "    \n",
    "    response = openai.Completion.create(\n",
    "        engine=\"text-davinci-003\",\n",
    "        prompt=prompt,\n",
    "        max_tokens=50,\n",
    "        n=1,\n",
    "        stop=None,\n",
    "        temperature=0.7,\n",
    "    )\n",
    "        \n",
    "    summary = response.choices[0].text.strip()\n",
    "    return summary\n",
    "\n",
    "def generate_summary(paragraph):\n",
    "    \n",
    "    # Tokenize sentences\n",
    "    review = nltk.sent_tokenize(paragraph)\n",
    "\n",
    "    prompt = f\"Give me a short summarize of the following review': {review}\"\n",
    "    \n",
    "    response = openai.Completion.create(\n",
    "        engine=\"text-davinci-003\",\n",
    "        prompt=prompt,\n",
    "        max_tokens=50,\n",
    "        n=1,\n",
    "        stop=None,\n",
    "        temperature=0.7,\n",
    "    )\n",
    "        \n",
    "    summary = response.choices[0].text.strip()\n",
    "    return summary\n",
    "\n",
    "def generate_report(paragraph):\n",
    "    \n",
    "    # Tokenize sentences\n",
    "    review = nltk.sent_tokenize(paragraph)\n",
    "\n",
    "    prompt = f\"Give me a few points of summary of the following, including the merits and the problems': {review}\"\n",
    "    \n",
    "    response = openai.Completion.create(\n",
    "        engine=\"text-davinci-003\",\n",
    "        prompt=prompt,\n",
    "        max_tokens=2000,\n",
    "        n=1,\n",
    "        stop=None,\n",
    "        temperature=0.7,\n",
    "    )\n",
    "        \n",
    "    summary = response.choices[0].text.strip()\n",
    "    return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WS9UOXX_UlCW",
    "outputId": "e54d44bd-2bcf-4479-bb01-0fb0722af5df"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tourism Impact\n"
     ]
    }
   ],
   "source": [
    "# audio_file= open(audio_file_name, \"rb\")\n",
    "\n",
    "# transcript = openai.Audio.transcribe(\"whisper-1\", audio_file)\n",
    "\n",
    "# # Convert the JSON object to a JSON-formatted string\n",
    "# transcript = json.dumps(transcript)\n",
    "# # Save to txt file\n",
    "# with open(\"input.txt\", \"w\") as file:\n",
    "#     file.write(transcript)\n",
    "\n",
    "#Uncomment below to run each\n",
    "\n",
    "# generate_sentiment_score(transcript)\n",
    "generate_topic(transcript)\n",
    "# generate_theme(transcript)\n",
    "# generate_summary(transcript)\n",
    "# generate_report(transcript)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "id": "vRVB1HxJ5nk8",
    "outputId": "fb0a8d82-6657-4ab0-ac47-841a47ffe09c"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'This review is about the impact of COVID-19 on the tourism industry, particularly in Waipa District. It covers the economic impact of the virus including job losses and business closures, the loss of international visitors, the impact of airline'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_summary(transcript)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "MgqJhJtNArE7",
    "outputId": "6a6c11bf-3ca7-4130-a0e8-38a6f5383afd"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'Theme: The Impact of COVID-19 on the Tourism Industry'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_theme(transcript)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
